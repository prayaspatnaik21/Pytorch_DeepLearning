{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7YB4iZFyLre"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import  torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image,ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMquc3roR81O"
      },
      "source": [
        "#Setting Up DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sIb3zzftcDb"
      },
      "source": [
        "\n",
        "\n",
        "1.   ImageNet is a standard collection of images used to train neural networks. It contains more than 14 million images and 20,000 image categories.\n",
        "2.   A dataset is a python class that allows us to get at the data we are supplying to the neural network.\n",
        "3.  A data loader is what feeds data from the dataset into the network.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Built-n dataset of torchvision.datasets.ImageFolder to quickly set up some dataloaders of download cat and fish images\n",
        "\n",
        "*   Check_image is a quick little functions that is passed to the is_valid_file parameter in the ImageFolder and will do a sanity check to make sure PIL can actually open the file.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhmOLuMoSBCd"
      },
      "outputs": [],
      "source": [
        "def check_image(path):\n",
        "  try:\n",
        "    im = Image.open(path)\n",
        "    return True\n",
        "  except:\n",
        "    return False()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lmLzh90UCGy"
      },
      "source": [
        "\n",
        "\n",
        "*   Resize to 64*64\n",
        "*   Convert to tensor\n",
        "*   Normalize using ImageNet mean & std\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKa1l8kST_wL"
      },
      "outputs": [],
      "source": [
        "image_transformation = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485,0.456,0.406],\n",
        "                        std=[0.229,0.224,0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3PwW6xdOUBxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchvision package includes a class called ImageFolder that does pretty much \n",
        "\n",
        "*  Torchvision package includes a class called ImageFolder that does pretty much everything , providing images are in a structure where each directory is a label.\n",
        "*   It allows us to specify a list of transforms that will be applied to an image before it gets fed into the neural network.The Default transform is to take image data and turn it into a tensor.\n",
        "*   Training set - Used in the training pass to update the model\n",
        "*   Validation set- Used to Evaluate how the model is generalizing to the problem domain, rather than fitting to the training data. It is not used to update the model directly.\n",
        "*   Test Set - A final dataset that provides a final evaluation of the model's performance after training its complete.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xPLrtHQ7TRlE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WXShDY8mnH7"
      },
      "outputs": [],
      "source": [
        "train_data_path = \"/content/drive/MyDrive/Datasets/train/\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=image_transformation,is_valid_file = check_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data_path = \"/content/drive/MyDrive/Datasets/val/\"\n",
        "validation_data = torchvision.datasets.ImageFolder(root=validation_data_path,transform=image_transformation,is_valid_file =  check_image)"
      ],
      "metadata": {
        "id": "PbIN5MHMMqJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9NfSy_vnCJc"
      },
      "outputs": [],
      "source": [
        "test_data_path = \"/content/drive/MyDrive/Datasets/test/\"\n",
        "test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform = image_transformation,is_valid_file = check_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Batch Size tells how  many images will go through the network before we train and update it.\n",
        "*   By default Pytorch's data loader are set to batch_size of 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "CX7j_DvUi23b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX3dBVQ2BR79"
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcFkNRh7BVWw"
      },
      "outputs": [],
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(train_data,batch_size = batch_size)\n",
        "validation_data_loader = torch.utils.data.DataLoader(validation_data,batch_size = batch_size)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data,batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Activation functions is a way of inserting non-linearity into our system.\n",
        "\n"
      ],
      "metadata": {
        "id": "QVqufmfvqL0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First Model SimpleNet\n",
        "\n",
        "\n",
        "1.   SimpleNet is a very simple combination of three linear layers and ReLu activations betwenn them.\n",
        "2.   Class torch.nn.Linear(in_features,out_features,bias=True,device=None,dtype=None)\n",
        "\n",
        "      *   Applies a Linear Transformation to the incoming data y = x*AT + b\n",
        "      *   in_features - size of each input sample\n",
        "      *   out_feature - size of each output sample\n",
        "      *   bias - if set to False , the layer will not learn an additive bias.Default: True\n",
        "      *   Shape - Input(*,Hin) where * means any number of  dimensions includng None and Hin = in_features.\n",
        "      *   Output:(*,Hout) where all but the last dimensions are the same shape as the input and Hout = out_features\n",
        "      *   Linear.weight - The learnable weights of the module of shape(out_features,in_features).The values are initialized from U(-sqrt(k),sqrt(k)),\n",
        "      where k = 1/in_features.\n",
        "      *  Linear.bias = the learnable bias of the shape (out_features). initialized from U(-sqrt(k),sqrt(k)) where k = 1/in_features.\n",
        "\n",
        "\n",
        "3.   Init function calls the superclass constructor and the three fully connected layers.\n",
        "4.   Forward method describes how data flows through the network in both training and making predictionns(inferences).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ny-1TlEbWbor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SimpleNet,self).__init__()\n",
        "    self.fc1 = nn.Linear(12288,84)\n",
        "    self.fc2 = nn.Linear(84,50)\n",
        "    self.fc3 = nn.Linear(50,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1,12288)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Apl7EgCUWczq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simpleNetObect  = SimpleNet()"
      ],
      "metadata": {
        "id": "TQKsYXZAbeAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss Functions\n",
        "\n",
        "\n",
        "*   CrossEntropyLoss is the built-in loss function recommeneded for Multi-Class Categorization.\n",
        "*   It also incorporates softmax() as part of its operation.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UNQJM6OzcCCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create an Optimizer\n",
        "\n",
        "\n",
        "*   To perform the updates on the neural network , we use an optimizer.\n",
        "*   Issues - Trapped in local minima.\n",
        "*   Key Improvements that Adam makes is that it uses a learning rate per parameter and adapts that learning rate depending on the rate of change of those parameters.\n",
        "*   It keeps an exponentially decaying list of gradients and the square of those gradients and uses those to scale the global learning rate that Adam is working with.\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e5Ibe2aGsYfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(simpleNetObect.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "aujgylyYcFMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Copy the model to CPU\n",
        "\n",
        "\n",
        "*   Copy the model to the GPU if available\n",
        "*   PyTorch by default does CPU based calculations.\n",
        "*   To take advantage of the GPU, we need to move our input tensors and the model iself to the GPU by explicitly using the to() method.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h_LwqQbst1_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "simpleNetObect.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6KvnLT-t0Z0",
        "outputId": "b25e8775-614d-411a-d319-44089e3ab905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNet(\n",
              "  (fc1): Linear(in_features=12288, out_features=84, bias=True)\n",
              "  (fc2): Linear(in_features=84, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "30GVJFDIuLyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training\n",
        "\n",
        "\n",
        "*   Trains the model\n",
        "*   Copying batches to the GPU if required\n",
        "*   Calculating Loss\n",
        "*   Optimizing the network and perform validation at each epoch.\n",
        "\n",
        "\n",
        "*   To compute the gradients,we call the backward() method on the model.\n",
        "*   The optimizer.step() method uses those gradients afterward to perform the adjustments of the weight.\n",
        "*   It turns out that the calculated gradients accumulate by default meaning, if we didn't zero the gradients at the end of the batch's iteration  the next batch would have to deal with this batch's gradients as well as its own and the batch after that would have to cope wiwth the previous two, and so on.\n",
        "*   Use zero_grad()to make sure they are reset to zero after we are done with our loop.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KZIwll6xuRfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,loss_fn,train_loader,val_loader,epochs = 20,device=\"cpu\"):\n",
        "  for epoch in range(1,epochs+1):\n",
        "    training_loss = 0.0\n",
        "    validation_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      inputs,targets = batch\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      output = model(inputs)\n",
        "      loss = loss_fn(output,targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      training_loss += loss.data.item() * inputs.size(0)\n",
        "    training_loss /= len(train_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_examples = 0\n",
        "\n",
        "    for batch in val_loader:\n",
        "      inputs , targets = batch\n",
        "      inputs = inputs.to(device)\n",
        "      output = model(inputs)\n",
        "      targets = targets.to(device)\n",
        "      loss = loss_fn(output,targets)\n",
        "      validation_loss += loss.data.item() * inputs.size(0)\n",
        "      correct = torch.eq(torch.max(F.softmax(output,dim=1),dim=1)[1],targets)\n",
        "      num_correct += torch.sum(correct).item()\n",
        "      num_examples += correct.shape[0]\n",
        "    validation_loss /= len(validation_data_loader.dataset)\n",
        "\n",
        "    print('Epoch:{},Training Loss :{:.2f},Validation Loss: {:.2f},accuracy = {:.2f}'.format(epoch,training_loss,validation_loss,num_correct/num_examples))\n"
      ],
      "metadata": {
        "id": "fiBNQXbZumpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(simpleNetObect,optimizer,torch.nn.CrossEntropyLoss(),train_data_loader,validation_data_loader,epochs = 20 , device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wgnIUVryzcq",
        "outputId": "ae48c05a-5547-4462-9d82-9d1706dd2496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1,Training Loss :2.35,Validation Loss: 6.26,accuracy = 0.29\n",
            "Epoch:2,Training Loss :3.21,Validation Loss: 1.69,accuracy = 0.69\n",
            "Epoch:3,Training Loss :1.22,Validation Loss: 0.94,accuracy = 0.50\n",
            "Epoch:4,Training Loss :0.69,Validation Loss: 0.63,accuracy = 0.75\n",
            "Epoch:5,Training Loss :0.42,Validation Loss: 0.71,accuracy = 0.68\n",
            "Epoch:6,Training Loss :0.40,Validation Loss: 0.63,accuracy = 0.78\n",
            "Epoch:7,Training Loss :0.29,Validation Loss: 0.68,accuracy = 0.75\n",
            "Epoch:8,Training Loss :0.29,Validation Loss: 0.64,accuracy = 0.75\n",
            "Epoch:9,Training Loss :0.23,Validation Loss: 0.68,accuracy = 0.74\n",
            "Epoch:10,Training Loss :0.22,Validation Loss: 0.69,accuracy = 0.73\n",
            "Epoch:11,Training Loss :0.20,Validation Loss: 0.68,accuracy = 0.73\n",
            "Epoch:12,Training Loss :0.16,Validation Loss: 0.72,accuracy = 0.73\n",
            "Epoch:13,Training Loss :0.16,Validation Loss: 0.69,accuracy = 0.74\n",
            "Epoch:14,Training Loss :0.13,Validation Loss: 0.73,accuracy = 0.72\n",
            "Epoch:15,Training Loss :0.12,Validation Loss: 0.73,accuracy = 0.73\n",
            "Epoch:16,Training Loss :0.11,Validation Loss: 0.72,accuracy = 0.75\n",
            "Epoch:17,Training Loss :0.09,Validation Loss: 0.78,accuracy = 0.72\n",
            "Epoch:18,Training Loss :0.09,Validation Loss: 0.74,accuracy = 0.74\n",
            "Epoch:19,Training Loss :0.07,Validation Loss: 0.77,accuracy = 0.74\n",
            "Epoch:20,Training Loss :0.05,Validation Loss: 0.80,accuracy = 0.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making Prediction\n",
        "\n",
        "\n",
        "*   Unsqueeze adds a new dimension at the front of our tensor\n",
        "*   Argmax returns the index of the highest value of the tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "INQhwmhbIhou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['cat','fish']\n",
        "image = Image.open(\"/content/drive/MyDrive/Datasets/test/cat/261385269_5f0e6578b2.jpg\")\n",
        "image = image_transformation(image).to(device)\n",
        "image = torch.unsqueeze(image,0)\n",
        "\n",
        "simpleNetObect.eval()\n",
        "prediction = F.softmax(simpleNetObect(image),dim=1)\n",
        "prediction = prediction.argmax()\n",
        "print(labels[prediction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PHJWrVNzBli",
        "outputId": "6369e7c7-7490-4b01-a350-639796408dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving Models\n",
        "\n",
        "*   Save the model using save or just the parameters using state_dic.\n",
        "*   save function store the current parameters and model structure.\n",
        "*   Load function stores both the parameters and the structure of the model to a file.This might be a problem if you change the structure of the model at a later point.\n",
        "*   It is more common to save a model's state_dict instead.This is a standard python dict that contains the map of each layer's parameters in the model.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "64bFFL_3KLia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(simpleNetObect, \"/content/drive/MyDrive/Colab Notebooks/Pytorch/temp/Model.docx\")\n",
        "simpleNetObect = torch.load(\"/content/drive/MyDrive/Colab Notebooks/Pytorch/temp/Model.docx\")"
      ],
      "metadata": {
        "id": "emLL5QzOJcDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(simpleNetObect.state_dict(),\"/content/drive/MyDrive/Colab Notebooks/Pytorch/temp/Model.docx\")\n",
        "simpleNetObect = SimpleNet()\n",
        "simpleNetObect_state_dict = torch.load(\"/content/drive/MyDrive/Colab Notebooks/Pytorch/temp/Model.docx\")\n",
        "simpleNetObect.load_state_dict(simpleNetObect_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5ubZonRLDUK",
        "outputId": "a9a2b903-30f1-46d1-fc44-b928cf2d0849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JckwTM_NNu5Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pytorch_ImageClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}